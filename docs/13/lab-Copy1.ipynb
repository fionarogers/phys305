{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Machine Learning Lab: A Simple Neural Network on MNIST with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this lab, we will\n",
    "1. Downloads and loads MNIST into NumPy arrays (if it doesn't already exist locally).\n",
    "2. Builds a simple Multi-Layer Perceptron in JAX.\n",
    "3. Trains the network on MNIST.\n",
    "4. Evaluates the performance on test data.\n",
    "5. Provides a custom inference function for your own handwriting images.\n",
    "\n",
    "This lab is based on a [JAX example](https://github.com/jax-ml/jax/blob/main/examples/mnist_classifier_fromscratch.py).\n",
    "Please notice that MNIST is the \"hello world\" for machine learning, and there are **many many** examples available online, including some simplier ones that use libraries:\n",
    "[JAX with pre-built optimizers](https://github.com/jax-ml/jax/blob/main/examples/mnist_classifier.py), [FLAX](https://flax.readthedocs.io/en/latest/mnist_tutorial.html), and [pytorch](https://github.com/pytorch/examples/tree/main/mnist), [Keras](https://www.tensorflow.org/datasets/keras_example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## MNIST Data Loader\n",
    "\n",
    "We start by downloading the MNIST data set and store it locally.\n",
    "Our data loader will parse, reshape, normalize them, and return them in NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.gz exists; skip download\n",
      "train-labels-idx1-ubyte.gz exists; skip download\n",
      "t10k-images-idx3-ubyte.gz exists; skip download\n",
      "t10k-labels-idx1-ubyte.gz exists; skip download\n"
     ]
    }
   ],
   "source": [
    "from os.path import isfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "\n",
    "# File names\n",
    "files = {\n",
    "    \"train_images\": \"train-images-idx3-ubyte.gz\",\n",
    "    \"train_labels\": \"train-labels-idx1-ubyte.gz\",\n",
    "    \"test_images\":  \"t10k-images-idx3-ubyte.gz\",\n",
    "    \"test_labels\":  \"t10k-labels-idx1-ubyte.gz\",\n",
    "}\n",
    "\n",
    "for key, file in files.items():\n",
    "    if not isfile(file):\n",
    "        url = base_url + file\n",
    "        print(f\"Downloading {url} to {file}...\")\n",
    "        urlretrieve(url, file)\n",
    "    else:\n",
    "        print(f\"{file} exists; skip download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import array\n",
    "from jax import numpy as np\n",
    "\n",
    "# Parsing functions\n",
    "def parse_labels(file):\n",
    "    with gzip.open(file, \"rb\") as fh:\n",
    "        _magic, num_data = struct.unpack(\">II\", fh.read(8))\n",
    "        # Read the label data as 1-byte unsigned integers\n",
    "        return np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
    "\n",
    "def parse_images(file):\n",
    "    with gzip.open(file, \"rb\") as fh:\n",
    "        _magic, num_data, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
    "        # Read the image data as 1-byte unsigned integers\n",
    "        images = np.array(array.array(\"B\", fh.read()), dtype=np.uint8)\n",
    "        # Reshape to (num_data, 28, 28)\n",
    "        images = images.reshape(num_data, rows, cols)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse raw data\n",
    "\n",
    "train_images_raw = parse_images(files[\"train_images\"])\n",
    "train_labels_raw = parse_labels(files[\"train_labels\"])\n",
    "\n",
    "test_images_raw  = parse_images(files[\"test_images\"])\n",
    "test_labels_raw  = parse_labels(files[\"test_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the images, i.e., flatten and normalize images to [0, 1]\n",
    "def standardize(images):\n",
    "    return images.reshape(-1, 28*28).astype(np.float32) / 255\n",
    "\n",
    "train_images = standardize(train_images_raw)\n",
    "test_images  = standardize(test_images_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "def one_hot(labels, num_classes=10):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "train_labels = one_hot(train_labels_raw, 10).astype(np.float32)\n",
    "test_labels  = one_hot(test_labels_raw,  10).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Visualize Some Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x73a5b4e7a120>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images_raw[879,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x73a5b6f55a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images_raw[0,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Define a Simple Neural Network in JAX\n",
    "\n",
    "In this subsection, we introduce the core function needed to **initialize** the parameters of a multi-layer network.\n",
    "Our network will have multiple layers, each characterized by a weight matrix `W` and a bias vector `b`.\n",
    "We will use random initialization scaled by a small factor to ensure stable starting values for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "\n",
    "def init_params(scale, layer_sizes, rng=npr.RandomState(0)):\n",
    "    \"\"\"\n",
    "    Initialize the parameters (weights and biases) for each layer in the network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    scale : float\n",
    "        A scaling factor to control the initial range of the weights.\n",
    "    layer_sizes : list of int\n",
    "        The sizes of each layer in the network.\n",
    "        e.g., [784, 1024, 1024, 10] means:\n",
    "            - Input layer: 784 units\n",
    "            - Hidden layer 1: 1024 units\n",
    "            - Hidden layer 2: 1024 units\n",
    "            - Output layer: 10 units\n",
    "    rng : numpy.random.RandomState\n",
    "        Random state for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    params : list of tuples (W, b)\n",
    "        Each tuple contains (W, b) for a layer.\n",
    "        - W is a (input_dim, output_dim) array of weights\n",
    "        - b is a (output_dim,) array of biases\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (scale * rng.randn(m, n), scale * rng.randn(n))\n",
    "        for m, n in zip(layer_sizes[:-1], layer_sizes[1:])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "How it works:\n",
    "* We specify a list of layer sizes: for example, `[784, 1024, 1024, 10]`.\n",
    "* For each pair of consecutive sizes `(m, n)`, we create a weight matrix W of shape `(m, n)` and a bias vector `b` of shape `(n,)`.\n",
    "* Multiplying by scale ensures that initial values are not too large, which helps prevent numerical issues early in training.\n",
    "* We store all `(W, b)` pairs in a list, one pair per layer, to be used throughout training and inference.\n",
    "\n",
    "By calling `init_params(scale, layer_sizes)`, you obtain an easy-to-manipulate structure that keeps all the parameters needed for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network architecture and hyperparameters\n",
    "\n",
    "layer_sizes = [784, 1024, 1024, 10]  # 2 hidden layers\n",
    "param_scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "\n",
    "params = init_params(param_scale, layer_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Forward Pass: The `predict` Function\n",
    "\n",
    "Once the network parameters are initialized, we need a function to perform the **forward pass**, producing an output for each batch of inputs.\n",
    "Below, we define `predict` to process data through multiple layers—using a `tanh` activation on the hidden layers—and compute a **log-softmax** on the final output layer for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as np\n",
    "from jax.scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(params, inputs):\n",
    "    \"\"\"\n",
    "    Compute the network's output logits for a batch of inputs, then subtract\n",
    "    log-sum-exp for numerical stability (log-softmax).\n",
    "\n",
    "    Network architecture:\n",
    "      - Hidden layers use tanh activation\n",
    "      - Output layer is linear (we'll do log-softmax here)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : list of (W, b) tuples\n",
    "        Network's parameters for each layer.\n",
    "    inputs : np.ndarray\n",
    "        A batch of input data of shape (batch_size, input_dim).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Log probabilities of shape (batch_size, 10).\n",
    "    \"\"\"\n",
    "    activations = inputs\n",
    "\n",
    "    # Hidden layers\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = np.dot(activations, w) + b\n",
    "        activations = np.tanh(outputs)\n",
    "\n",
    "    # Final layer (logits)\n",
    "    final_w, final_b = params[-1]\n",
    "    logits = np.dot(activations, final_w) + final_b\n",
    "\n",
    "    # Log-Softmax: subtract logsumexp for numerical stability\n",
    "    return logits - logsumexp(logits, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "* Hidden Layers (`tanh`): Each hidden layer applies a linear transformation (`np.dot(activations, w) + b`) followed by the hyperbolic tangent activation function (`np.tanh`).\n",
    "* Final Layer (`logits`): The last layer's output is not activated by tanh; instead, we use it directly as logits.\n",
    "* Log-Softmax: We transform logits to log probabilities by subtracting the logsumexp(logits) along the class dimension.\n",
    "  This step ensures numerical stability and can be directly used to compute losses like cross-entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Defining the Loss Function\n",
    "\n",
    "To guide training, we need a **loss function** that measures how well our network's predictions match the true labels.\n",
    "This is like $\\chi^2$ when we need to fit a curve.\n",
    "Below, we define a function that computes the **negative log-likelihood** (NLL) over a batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, batch):\n",
    "    \"\"\"\n",
    "    Computes the average negative log-likelihood loss for a batch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : list of (W, b) tuples\n",
    "        The network's parameters.\n",
    "    batch : tuple (inputs, targets)\n",
    "        - inputs: np.ndarray of shape (batch_size, 784)\n",
    "        - targets: np.ndarray of shape (batch_size, 10) (one-hot labels)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Mean negative log-likelihood over the batch.\n",
    "    \"\"\"\n",
    "    inputs, targets = batch\n",
    "    preds = predict(params, inputs)\n",
    "    \n",
    "    # preds are log-probs, multiply with one-hot targets and sum -> log-likelihood\n",
    "    return -np.mean(np.sum(preds * targets, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "* Inputs and Targets: A single batch typically consists of a set of input vectors (inputs) and corresponding one-hot encoded labels (targets).\n",
    "* Forward Pass: We call predict(params, inputs), which returns the log probabilities for each class.\n",
    "* NLL Computation: We multiply the log probabilities by the one-hot labels (so we only pick out the log probability of the correct class for each example). Summing these values (log-likelihood) and then negating yields the negative log-likelihood.\n",
    "* Mean Value: We take the average across the batch, yielding a scalar loss.\n",
    "\n",
    "This loss metric drives parameter updates: minimizing it pushes the network to assign higher probabilities to the correct classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance\n",
    "\n",
    "While the network is trained by minimizing the negative log-likelihood (NLL), we often monitor **accuracy** to get an intuitive sense of model performance.\n",
    "The function below calculates the fraction of samples in a batch that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(params, batch):\n",
    "    \"\"\"\n",
    "    Computes classification accuracy of the network on a given batch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : list of (W, b) tuples\n",
    "        The network's parameters.\n",
    "    batch : tuple (inputs, targets)\n",
    "        - inputs: np.ndarray (batch_size, 784)\n",
    "        - targets: np.ndarray (batch_size, 10) (one-hot labels)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Fraction of correctly classified samples.\n",
    "    \"\"\"\n",
    "    inputs, targets = batch\n",
    "    target_class = np.argmax(targets, axis=1)  # ground truth index\n",
    "    predicted_class = np.argmax(predict(params, inputs), axis=1)\n",
    "    return np.mean(predicted_class == target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "* Predicted Class:\n",
    "  * We use predict(params, inputs) to get log probabilities.\n",
    "  * Taking the argmax across the class dimension finds the class with the highest log probability.\n",
    "* Compare to Ground Truth:\n",
    "  * We similarly get the ground truth label indices from the one-hot targets by using np.argmax(targets, axis=1).\n",
    "* Accuracy Computation:\n",
    "  * We compute the fraction of instances where the predicted class matches the ground-truth class.\n",
    "  * This value ranges between 0 (no correct predictions) and 1 (perfect classification).\n",
    "\n",
    "Monitoring accuracy alongside the loss offers a more intuitive measure of how well the model performs on a classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Gradient Descent for Training: JIT-Compiled Update Function\n",
    "\n",
    "To optimize our network, we can use **Stochastic Gradient Descent (SGD)**, updating parameters in the direction that reduces the loss.\n",
    "This is essentially the same algorithm we implemented in our optimization class!\n",
    "Except we only implement a single step for now.\n",
    "Here, we decorate our update step with `@jit` to compile it for efficient execution on CPU or GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jit, grad\n",
    "\n",
    "@jit\n",
    "def update(params, batch, step_size):\n",
    "    \"\"\"\n",
    "    Single step of gradient-based parameter update using simple SGD.\n",
    "\n",
    "    grad(loss)(params, batch) computes the gradient of the loss function\n",
    "    with respect to the parameters for the given batch.\n",
    "    \"\"\"\n",
    "    grads = grad(loss)(params, batch)\n",
    "    return [\n",
    "        (w - step_size * dw, b - step_size * db)\n",
    "        for (w, b), (dw, db) in zip(params, grads)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Key Ideas:\n",
    "* grad(loss) automatically differentiates the loss function w.r.t. all parameters (params), yielding parameter gradients.\n",
    "* SGD Update:\n",
    "  * For each weight w, we update it by w - step_size * dw.\n",
    "  * Similarly for each bias b.\n",
    "* `@jit` Decorator:\n",
    "  * Compiles the update step using XLA (Accelerated Linear Algebra).\n",
    "  * Improves performance by running the update efficiently on CPU/GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## Preparing the Batching Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # the number of samples per parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = train_images.shape[0]\n",
    "num_batches = num_train // batch_size\n",
    "\n",
    "def get_batch(rng=npr.RandomState(0)):\n",
    "    \"\"\"\n",
    "    Generator function that yields shuffled batches indefinitely.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Randomly permute the indices\n",
    "        perm = rng.permutation(num_train)\n",
    "        for i in range(num_batches):\n",
    "            batch_idx = perm[i*batch_size : (i+1)*batch_size]\n",
    "            # Yield a tuple (inputs, labels) for this batch\n",
    "            yield (train_images[batch_idx], train_labels[batch_idx])\n",
    "\n",
    "train_batch_generator = get_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "* Shuffling: Each epoch, we shuffle the training indices (`perm = rng.permutation(num_train)`) to ensure that each mini-batch contains a random subset of the dataset.\n",
    "* Batch Extraction: We slice the permuted indices into chunks of size batch_size.\n",
    "  Each chunk defines which samples from train_images and train_labels go into the current batch.\n",
    "\n",
    "By continuously yielding batches in an infinite `while True:` loop, we can keep calling `next(train_batch_generator)` without manually restarting the data pipeline each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## The Training Loop\n",
    "\n",
    "Now we can train our neural network by iterating over epochs and batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001  # the number of times we iterate over the entire training dataset.\n",
    "num_epochs    = 5      # the number of samples per parameter update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 in 9.84 sec\n",
      "Training accuracy: 0.8837\n",
      "Test accuracy:     0.8897\n",
      "Epoch 1 in 9.82 sec\n",
      "Training accuracy: 0.8908\n",
      "Test accuracy:     0.8939\n",
      "Epoch 2 in 9.80 sec\n",
      "Training accuracy: 0.8965\n",
      "Test accuracy:     0.8987\n",
      "Epoch 3 in 9.67 sec\n",
      "Training accuracy: 0.9014\n",
      "Test accuracy:     0.9030\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time()\n",
    "\n",
    "    # Go through the entire training set\n",
    "    for _ in range(num_batches):\n",
    "        batch_data = next(train_batch_generator)\n",
    "        params = update(params, batch_data, step_size=learning_rate)\n",
    "\n",
    "    epoch_time = time() - start_time\n",
    "\n",
    "    # Evaluate training and test accuracy\n",
    "    train_acc = accuracy(params, (train_images, train_labels))\n",
    "    test_acc = accuracy(params, (test_images, test_labels))\n",
    "\n",
    "    print(f\"Epoch {epoch} in {epoch_time:0.2f} sec\")\n",
    "    print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test accuracy:     {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Breaking this down:\n",
    "* Epoch Loop: We run `for epoch in range(num_epochs):` to repeat the training process multiple times over the dataset.\n",
    "* Batch Loop: For each epoch, we execute a loop `for _ in range(num_batches):` to process all training batches.\n",
    "* Parameter Update:\n",
    "  * We call next(train_batch_generator) to obtain the next (inputs, labels) batch.\n",
    "  * We then update the network parameters by calling:\n",
    "    `params = update(params, batch_data, step_size=learning_rate)`\n",
    "  * This performs a single SGD step, moving each parameter slightly toward reducing the loss.\n",
    "* Timing: We measure how long each epoch takes by recording the start time with `time()` and subtracting from the end time.\n",
    "* Evaluation: After processing all batches for the epoch, we compute:\n",
    "  * `train_acc`: Accuracy on the entire training set.\n",
    "  * `test_acc`: Accuracy on the reserved test set.\n",
    "* Logging: We print out the epoch number, epoch duration, and both training and test accuracies.\n",
    "  Monitoring test accuracy helps assess how well the model generalizes beyond the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "At this point, we have a fully operational training pipeline for MNIST.\n",
    "You can experiment with different hyperparameters (e.g., learning rate, batch size, number of epochs, network architecture) to see how they affect model performance.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing a Custom Image\n",
    "\n",
    "To run inference on your own handwriting, we first need to **load** the image from disk and **convert** it into a format suitable for our trained network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_image(file):\n",
    "    \"\"\"\n",
    "    Loads a grayscale image from `file`, resizes it to 28x28,\n",
    "    and converts it to a (784,) float32 array with values in [0, 1].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str\n",
    "        Path to the image file (e.g., a PNG or JPG).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        An array of shape (1, 784) containing normalized pixel values\n",
    "        suitable as input to our trained model.\n",
    "    \"\"\"\n",
    "    # Convert the image to grayscale and resize to 28x28\n",
    "    img = Image.open(file).convert('L').resize((28, 28))\n",
    "\n",
    "    # Convert to a NumPy array and normalize pixel intensities to [0, 1]\n",
    "    arr = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "    # Flatten the 28x28 image into a single 784-dimensional vector\n",
    "    arr = arr.flatten()\n",
    "\n",
    "    # Reshape to (1, 784) to match the model's expected input batch shape\n",
    "    return np.array([arr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Predicting the Digit Class\n",
    "\n",
    "With a properly formatted image, we can classify it using our trained model's parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_digit(params, file_path):\n",
    "    \"\"\"\n",
    "    Predict the digit class for a custom handwritten image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : list of (W, b) tuples\n",
    "        The trained network parameters.\n",
    "    file_path : str\n",
    "        Path to the custom image file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The predicted digit label (0 through 9).\n",
    "    \"\"\"\n",
    "    # Convert the image to a suitable NumPy array\n",
    "    arr_np = load_image(file_path)\n",
    "    \n",
    "    # Use our 'predict' function to get log probabilities for each class\n",
    "    log_probs = predict(params, arr_np)  # shape: (1, 10)\n",
    "    \n",
    "    # Select the digit class with the highest log probability\n",
    "    return int(np.argmax(log_probs, axis=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    ":::{exercise}\n",
    "\n",
    "1. Capture or scan your handwritten digit and save as \"sample.png\".\n",
    "2. Call the function:\n",
    "   ```\n",
    "   label = predict_digit(params, \"sample.png\")\n",
    "   print(f\"Predicted digit: {label}\")\n",
    "   ```\n",
    "3. Inspect the result: See whether the predicted label matches the actual digit you wrote.\n",
    "\n",
    "With these two functions, your MNIST-trained model can be used in real-world testing scenarios, allowing you to evaluate its performance on custom, hand-drawn images.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = predict_digit(params, \"sample.png\")\n",
    "print(f\"Predicted digit: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9d415-76c0-45a8-bd5c-bf954bb31119",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
